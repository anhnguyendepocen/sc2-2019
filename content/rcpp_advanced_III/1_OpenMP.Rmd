---
title: 1. Using OpenMP in Rcpp
weight: 1
output:
  blogdown::html_page:
    toc: true
---

<style>
body {
text-align: justify}
</style>

Here we describe some basic examples on the use of OpenMP to parallelise Rcpp code. We assume that the reader has some basic familiarity with OpenMP. If you need a refresher, have a look at [these notes](http://chryswoods.com/beginning_openmp/) from the Chris Wood.

### Basic examples

The following `Rcpp` program simply pauses the system for a `sec` seconds:
```{r}
library(Rcpp)
sourceCpp(code = '
#include <unistd.h>
#include <Rcpp.h>

// [[Rcpp::export(wait_a_second)]]
bool wait_a_second(int sec)
{
 for(size_t ii = 0; ii < sec; ii++)
 { 
  sleep(1);
 }
 return 1;
}
')

system.time( wait_a_second(2) )[3]
```
Where `sleep` is defined in `unistd.h`. The following function uses OpenMP to wait `sec` seconds on `ncores` in parallel:
```{r}
sourceCpp(code = '
#include <unistd.h>
#include <Rcpp.h>

// [[Rcpp::plugins(openmp)]]

// [[Rcpp::export(wait_a_second_omp)]]
bool wait_a_second_omp(int sec, int ncores)
{

 #if defined(_OPENMP)
  #pragma omp parallel num_threads(ncores)
  #pragma omp for
 #endif
 for(size_t ii = 0; ii < sec; ii++)
 { 
  sleep(1);
 }
 
 return 1;

 }
')
```
Not that we use the `Rcpp::plugins` to use OpenMP in the compilation of the function. The key OpenMP directives are 
```{r, eval = FALSE}
#pragma omp parallel num_threads(ncores)
```
which indicates the beginning of a parallel section, to be executed on `ncores` parallel thread and
```{r, eval = FALSE}
#pragma omp for
```
which tell the compiler that the `for` loop can be run in parallel. Let try if this works:
```{r, cache = TRUE}
system.time(wait_a_second_omp(4, 1))[3]

system.time(wait_a_second_omp(4, 4))[3]

system.time(wait_a_second_omp(16, 16))[3]
```
It seems so! Note that the speed up is linear in the number of threads in this case, because each thread is essentially doing nothing. That is, there is no competition for computing resources (i.e., floating-point processing units). To illustrate this, let us consider the following `Rcpp` function:
```{r}
sourceCpp(code = '
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export(allFiniteSeq)]]
bool allFiniteCpp(NumericVector x)
{

 size_t n = x.size();
 double out = 0;
 
 for(size_t ii = 0; ii < n; ii++)
 {
  out += x[ii];
 }
 
 return R_FINITE(out);

 }
')
```
which returns `TRUE` is all the elements of `x` are finite, `FALSE` otherwise. We can use OpenMP to parallelise it as follows:
```{r}
sourceCpp(code = '
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::plugins(openmp)]]

// [[Rcpp::export(allFiniteOMP)]]
bool allFiniteOMP(NumericVector x, int ncores)
{

 size_t n = x.size();
 double out = 0;
 
 #if defined(_OPENMP)
  #pragma omp parallel for num_threads(ncores)
 #endif
 for(size_t ii = 0; ii < n; ii++)
 {
  out += x[ii];
 }
 
 return R_FINITE(out);

 }
')
```
On my Intel i7-3820 3.60GHz CPU with 4 cores 8 threads I get the following timing: 
```{r, results='hide'}
x <- rnorm(1e7)

library(microbenchmark)
microbenchmark(all(is.finite(x)),
               allFiniteSeq(x),
               allFiniteOMP(x, 1), 
               allFiniteOMP(x, 4),
               allFiniteOMP(x, 8), 
               allFiniteOMP(x, 16),
               unit = 'relative')

# Unit: relative
#                 expr       min        lq       mean    median         uq       max neval
#    all(is.finite(x)) 18.837335 17.926310 13.9724439 17.217159 12.5035659 6.9339805   100
#      allFiniteSeq(x)  4.456039  4.290143  3.2039422  4.094480  2.5073357 1.9833380   100
#   allFiniteOMP(x, 1)  4.474725  4.296961  3.1659560  4.097613  2.5063335 1.8042596   100
#   allFiniteOMP(x, 4)  1.198264  1.243619  0.9922528  1.210484  0.7580539 1.0319743   100
#   allFiniteOMP(x, 8)  1.000000  1.000000  1.0000000  1.000000  1.0000000 1.0000000   100
#  allFiniteOMP(x, 16)  1.052189  1.122954  1.0166792  1.191262  0.9286961 0.6897481   100
```
Note that the `Rcpp` version is around 4 times fast that the `R` code, and that with 4 threads we get more or less are linear speed-up. However, the speed-up gains are negligible after that, and using 16 threads is actually detrimental. This is because a processor with 4 core has probably 4 physical floating-point (FLOP) units, hence trying to parallelise numerical computations on more than 4 threads does not make sense (the threads will start to compete for the same FLOP units). Note that above we used:
```{r, eval = FALSE}
#pragma omp parallel for num_threads(ncores)
```
which is a shortcut for:
```{r, eval = FALSE}
#pragma omp parallel num_threads(ncores)
#pragma omp for
```


### Parallel random number generation

aaa


```{r}
sourceCpp(code = '
#include <Rcpp.h>
#include <sitmo.h>

#ifdef _OPENMP
#include <omp.h>
#endif

// [[Rcpp::depends(sitmo)]]
// [[Rcpp::plugins(openmp)]]

// [[Rcpp::export(runif_sitmo_omp)]]
Rcpp::NumericVector runif_sitmo_omp(unsigned int n,
                                    unsigned int nstep,
                                    Rcpp::NumericVector seeds) {
  Rcpp::NumericVector out(n);
  
  unsigned int ncores = seeds.size();
  
  #ifdef _OPENMP
  #pragma omp parallel num_threads(ncores) if(ncores > 1)
  {
  #endif
  
   double mx = sitmo::prng::max();
   double tmp = 0;
   
   uint32_t coreseed = static_cast<uint32_t>(seeds[0]);
   
   #ifdef _OPENMP
    coreseed = static_cast<uint32_t>(seeds[omp_get_thread_num()]);
   #endif
   
   // Create a prng engine
   sitmo::prng eng(coreseed);
  
   #ifdef _OPENMP
    #pragma omp for schedule(static)
   #endif
   for(unsigned int ii = 0; ii < n; ++ii) {
     tmp = 0.0;
     for(unsigned int kk = 0; kk < nstep; ++kk){
      tmp += ((double) eng()) / mx;
     }
     out[ii] = tmp;
   }
    
  #ifdef _OPENMP
  }
  #endif
  
  return out;
}
')


```


```{r}
n <- 1e3
nstep <- 100

hist(runif_sitmo_omp(n, nstep = nstep, seeds = c(1.0)))
hist(runif_sitmo_omp(n, nstep = nstep, seeds = c(1.0, 2)))

hist(rowSums(matrix(runif(n*nstep), n, nstep)))

library(microbenchmark)
microbenchmark(rowSums(matrix(runif(n*nstep), n, nstep)),
               runif_sitmo_omp(n, nstep = nstep, seeds = 1),
               runif_sitmo_omp(n, nstep = nstep, seeds = 1:4)
               )
```

### Using OMP in R packages


