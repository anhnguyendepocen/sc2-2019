<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>1. Using OpenMP in Rcpp - SC2</title>
    <meta property="og:title" content="1. Using OpenMP in Rcpp - SC2">
    
    <meta name="twitter:card" content="summary">

    
      
    

    
      
      <meta property="description" content="Here we describe some basic examples on the use of OpenMP to parallelise Rcpp code. We assume that the reader has some basic familiarity with OpenMP. If you need a refresher, have a look at these &amp;hellip;">
      <meta property="og:description" content="Here we describe some basic examples on the use of OpenMP to parallelise Rcpp code. We assume that the reader has some basic familiarity with OpenMP. If you need a refresher, have a look at these &amp;hellip;">
      
    

    
    

    

    
    


<link href='//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



    <link rel="stylesheet" href="/sc2-2019/css/style.css" />
    <link rel="stylesheet" href="/sc2-2019/css/fonts.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Arvo">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Marcellus">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">

<link rel="stylesheet" href="/sc2-2019/css/custom.css" />

<link rel="icon" href="/sc1-2019/favicon.ico" type="image/x-icon" />























<nav class="breadcrumbs">
    
        <a href="https://mfasiolo.github.io/sc2-2019/">home / </a>
    
        <a href="https://mfasiolo.github.io/sc2-2019/rcpp_advanced_iii/">rcpp_advanced_iii / </a>
    
        <a href="https://mfasiolo.github.io/sc2-2019/rcpp_advanced_iii/1_openmp/">1_openmp / </a>
    
</nav>

  </head>

  
  <body class="sc2-2019">
    <header class="masthead">
      <h1><a href="/sc2-2019/">SC2</a></h1>

<p class="tagline">Statistical Computing 2</p>

      <nav class="menu">
  <input id="menu-check" type="checkbox" />
  <label id="menu-label" for="menu-check" class="unselectable">
    <span class="icon close-icon">✕</span>
    <span class="icon open-icon">☰</span>
    <span class="text">Menu</span>
  </label>
  <ul>
  
  
  <li><a href="/sc2-2019/">Home</a></li>
  
  <li><a href="/sc2-2019/rcpp/">Integrating R and C</a></li>
  
  <li><a href="/sc2-2019/rcpp_advanced_i/">Advanced Rcpp I</a></li>
  
  <li><a href="/sc2-2019/rcpp_advanced_ii/">Advanced Rcpp II</a></li>
  
  <li><a href="/sc2-2019/rcpp_advanced_iii/">Parallel Rcpp</a></li>
  
  
  </ul>
</nav>

    </header>

    <article class="main">
      <header class="title">
      
<h1>1. Using OpenMP in Rcpp</h1>

<h3>
</h3>
<hr>


      </header>





<div id="TOC">
<ul>
<li><a href="#basic-examples">Basic examples</a></li>
<li><a href="#parallel-random-number-generation-using-openmp">Parallel random number generation using OpenMP</a></li>
<li><a href="#using-openmp-in-r-packages">Using OpenMP in R packages</a></li>
</ul>
</div>

<style>
body {
text-align: justify}
</style>
<p>Here we describe some basic examples on the use of OpenMP to parallelise Rcpp code. We assume that the reader has some basic familiarity with OpenMP. If you need a refresher, have a look at <a href="http://chryswoods.com/beginning_openmp/">these notes</a> from the Chris Wood.</p>
<div id="basic-examples" class="section level3">
<h3>Basic examples</h3>
<p>The following <code>Rcpp</code> program simply pauses the system for a <code>sec</code> seconds:</p>
<pre class="r"><code>library(Rcpp)
sourceCpp(code = &#39;
#include &lt;unistd.h&gt;
#include &lt;Rcpp.h&gt;

// [[Rcpp::export(wait_a_second)]]
bool wait_a_second(int sec)
{
 for(size_t ii = 0; ii &lt; sec; ii++)
 { 
  sleep(1);
 }
 return 1;
}
&#39;)

system.time( wait_a_second(2) )[3]</code></pre>
<pre><code>## elapsed 
##       2</code></pre>
<p>Where <code>sleep</code> is defined in <code>unistd.h</code>. The following function uses OpenMP to wait <code>sec</code> seconds on <code>ncores</code> in parallel:</p>
<pre class="r"><code>sourceCpp(code = &#39;
#include &lt;unistd.h&gt;
#include &lt;Rcpp.h&gt;

// [[Rcpp::plugins(openmp)]]

// [[Rcpp::export(wait_a_second_omp)]]
bool wait_a_second_omp(int sec, int ncores)
{

 #if defined(_OPENMP)
  #pragma omp parallel num_threads(ncores)
  #pragma omp for
 #endif
 for(size_t ii = 0; ii &lt; sec; ii++)
 { 
  sleep(1);
 }
 
 return 1;

 }
&#39;)</code></pre>
<p>Not that we use the <code>Rcpp::plugins</code> to use OpenMP in the compilation of the function. The key OpenMP directives are</p>
<pre class="r"><code>#pragma omp parallel num_threads(ncores)</code></pre>
<p>which indicates the beginning of a parallel section, to be executed on <code>ncores</code> parallel thread and</p>
<pre class="r"><code>#pragma omp for</code></pre>
<p>which tell the compiler that the <code>for</code> loop can be run in parallel. Let try if this works:</p>
<pre class="r"><code>system.time(wait_a_second_omp(4, 1))[3]</code></pre>
<pre><code>## elapsed 
##       4</code></pre>
<pre class="r"><code>system.time(wait_a_second_omp(4, 4))[3]</code></pre>
<pre><code>## elapsed 
##   1.013</code></pre>
<pre class="r"><code>system.time(wait_a_second_omp(16, 16))[3]</code></pre>
<pre><code>## elapsed 
##   1.001</code></pre>
<p>It seems so! Note that the speed up is linear in the number of threads in this case, because each thread is essentially doing nothing. That is, there is no competition for computing resources (i.e., floating-point processing units). To illustrate this, let us consider the following <code>Rcpp</code> function:</p>
<pre class="r"><code>sourceCpp(code = &#39;
#include &lt;Rcpp.h&gt;
using namespace Rcpp;

// [[Rcpp::export(allFiniteSeq)]]
bool allFiniteCpp(NumericVector x)
{

 size_t n = x.size();
 double out = 0;
 
 for(size_t ii = 0; ii &lt; n; ii++)
 {
  out += x[ii];
 }
 
 return R_FINITE(out);

 }
&#39;)</code></pre>
<p>which returns <code>TRUE</code> is all the elements of <code>x</code> are finite, <code>FALSE</code> otherwise. We can use OpenMP to parallelise it as follows:</p>
<pre class="r"><code>sourceCpp(code = &#39;
#include &lt;Rcpp.h&gt;
using namespace Rcpp;

// [[Rcpp::plugins(openmp)]]

// [[Rcpp::export(allFiniteOMP)]]
bool allFiniteOMP(NumericVector x, int ncores)
{

 size_t n = x.size();
 double out = 0;
 
 #if defined(_OPENMP)
  #pragma omp parallel for num_threads(ncores)
 #endif
 for(size_t ii = 0; ii &lt; n; ii++)
 {
  out += x[ii];
 }
 
 return R_FINITE(out);

 }
&#39;)</code></pre>
<p>On my Intel i7-3820 3.60GHz CPU with 4 cores 8 threads I get the following timing:</p>
<pre class="r"><code>x &lt;- rnorm(1e7)

library(microbenchmark)
microbenchmark(all(is.finite(x)),
               allFiniteSeq(x),
               allFiniteOMP(x, 1), 
               allFiniteOMP(x, 4),
               allFiniteOMP(x, 8), 
               allFiniteOMP(x, 16),
               unit = &#39;relative&#39;)</code></pre>
<pre class="r"><code># Unit: relative
#                 expr       min        lq       mean    median         uq       max neval
#    all(is.finite(x)) 18.837335 17.926310 13.9724439 17.217159 12.5035659 6.9339805   100
#      allFiniteSeq(x)  4.456039  4.290143  3.2039422  4.094480  2.5073357 1.9833380   100
#   allFiniteOMP(x, 1)  4.474725  4.296961  3.1659560  4.097613  2.5063335 1.8042596   100
#   allFiniteOMP(x, 4)  1.198264  1.243619  0.9922528  1.210484  0.7580539 1.0319743   100
#   allFiniteOMP(x, 8)  1.000000  1.000000  1.0000000  1.000000  1.0000000 1.0000000   100
#  allFiniteOMP(x, 16)  1.052189  1.122954  1.0166792  1.191262  0.9286961 0.6897481   100</code></pre>
<p>Note that the <code>Rcpp</code> version is around 4 times fast that the <code>R</code> code, and that with 4 threads we get more or less are linear speed-up. However, the speed-up gains are negligible after that, and using 16 threads is actually detrimental. This is because a processor with 4 core has probably 4 physical floating-point (FLOP) units, hence trying to parallelise numerical computations on more than 4 threads does not make sense (the threads will start to compete for the same FLOP units). Note that above we used:</p>
<pre class="cpp"><code>#pragma omp parallel for num_threads(ncores)</code></pre>
<p>which is a shortcut for:</p>
<pre class="cpp"><code>#pragma omp parallel num_threads(ncores)
#pragma omp for</code></pre>
<p>One important thing to point out is that R’s C API and the Rcpp API are not thread-safe in generally. Hence, doing things such as:</p>
<pre class="cpp"><code>#pragma omp parallel
NumericVector x(10);</code></pre>
<p>(which creates a vector of length 10 on every thread) is not safe and might behave unexpectedly. Hence, it is preferrable to use the thread-safe data structures provided by the [RcppParallel R package]{<a href="https://cran.r-project.org/web/packages/RcppParallel/index.html" class="uri">https://cran.r-project.org/web/packages/RcppParallel/index.html</a>}, which will be discussed later in these notes. In the following section we show of to perform parallel randon number generation using OpenMP and a thread-safe RNG.</p>
</div>
<div id="parallel-random-number-generation-using-openmp" class="section level3">
<h3>Parallel random number generation using OpenMP</h3>
<p>As other parts of R’s C API, the R’s RNG is not thread safe. Hence <code>Rcpp</code> code such as:</p>
<pre class="cpp"><code>#pragma omp parallel
x = R::rbeta(a, b);</code></pre>
<p>will produce invalid results and might crash you R session. Hence, we must adopt a thread-safe RNG, such as the one provided by the [sitmo R package]{<a href="https://cran.r-project.org/web/packages/sitmo/index.html" class="uri">https://cran.r-project.org/web/packages/sitmo/index.html</a>}.</p>
<p>Before explaining how to use <code>sitmo</code> in parallel, let us consider the following sequential function:</p>
<pre class="r"><code>sourceCpp(code = &#39;
#include &lt;Rcpp.h&gt;
#include &lt;sitmo.h&gt;

// [[Rcpp::depends(sitmo)]]

// [[Rcpp::export(sumunif_sitmo)]]
Rcpp::NumericVector sumunif_sitmo(unsigned int n,
                                  unsigned int nstep,
                                  double seed) {
  Rcpp::NumericVector out(n);

  uint32_t coreseed = static_cast&lt;uint32_t&gt;(seed);
  sitmo::prng eng(coreseed);
  
  double mx = sitmo::prng::max();
  double tmp = 0;

   for(unsigned int ii = 0; ii &lt; n; ++ii) {
     tmp = 0.0;
     for(unsigned int kk = 0; kk &lt; nstep; ++kk){
      tmp += eng() / mx;
     }
     out[ii] = tmp;
   }
    
  return out;
}
&#39;)</code></pre>
<p>This function simply simulates <code>n</code> sums of <code>nstep</code> uniforms (0, 1) random variables. Hence, it is equivalent to the following R code:</p>
<pre class="r"><code>rowSums(matrix(runif(n*nstep), n, nstep))</code></pre>
<p>Let us examine the key steps in <code>runif_sitmo_omp</code>:</p>
<ul>
<li>we state that our code depends on the <code>sitmo</code> package via the <code>Rcpp::depends</code> attribute;</li>
<li>we convert the seed provided by R to type <code>uint32_t</code> via <code>uint32_t coreseed = static_cast&lt;uint32_t&gt;(seed);</code></li>
<li>we set up an RNG via <code>sitmo::prng eng(coreseed);</code></li>
<li>having done this, calling <code>eng()</code> will generate an uniform random number between 0 and <code>sitmo::prng::max()</code>,
hence we use <code>((double) eng()) / mx</code> to rescale the output of <code>eng()</code> to (0, 1).</li>
</ul>
<pre class="r"><code>n &lt;- 1e3
nstep &lt;- 100

par(mfrow = c(1, 2))
hist(rowSums(matrix(runif(n*nstep), n, nstep)), main = &quot;R&quot;, xlab = &quot;x&quot;)
hist(sumunif_sitmo(n, nstep = nstep, seed = 1), main = &quot;Sitmo&quot;, xlab = &quot;x&quot;)</code></pre>
<p><img src="/sc2-2019/rcpp_advanced_III/1_OpenMP_files/figure-html/unnamed-chunk-16-1.png" width="576" style="display: block; margin: auto;" />
The histograms show the Central Limit Theorem kicking in.</p>
<p>Let us not look at an parallel version:</p>
<pre class="r"><code>sourceCpp(code = &#39;
#include &lt;Rcpp.h&gt;
#include &lt;sitmo.h&gt;

#ifdef _OPENMP
#include &lt;omp.h&gt;
#endif

// [[Rcpp::depends(sitmo)]]
// [[Rcpp::plugins(openmp)]]

// [[Rcpp::export(sumunif_sitmo_omp)]]
Rcpp::NumericVector sumunif_sitmo_omp(unsigned int n,
                                      unsigned int nstep,
                                      Rcpp::NumericVector seeds) {
  Rcpp::NumericVector out(n);
  
  unsigned int ncores = seeds.size();
  
  #ifdef _OPENMP
  #pragma omp parallel num_threads(ncores)
  {
  #endif
  
   uint32_t coreseed = static_cast&lt;uint32_t&gt;(seeds[0]);
   
   #ifdef _OPENMP
    coreseed = static_cast&lt;uint32_t&gt;(seeds[omp_get_thread_num()]);
   #endif
   
   sitmo::prng eng(coreseed);
   
   double mx = sitmo::prng::max();
   double tmp = 0;
  
   #ifdef _OPENMP
    #pragma omp for
   #endif
   for(unsigned int ii = 0; ii &lt; n; ++ii) {
     tmp = 0.0;
     for(unsigned int kk = 0; kk &lt; nstep; ++kk){
      tmp += eng() / mx;
     }
     out[ii] = tmp;
   }
    
  #ifdef _OPENMP
  }
  #endif
  
  return out;
}
&#39;)</code></pre>
<p>Note that this code:</p>
<pre class="cpp"><code>#ifdef _OPENMP
#pragma omp parallel num_threads(ncores)
{
#endif</code></pre>
<p>marks the beginning of a parallel section of the code, hence the variable declared in this section (e.g, <code>coreseed</code>, <code>mx</code>) and the RNG <code>eng</code> is private to each parallel thread. This code:</p>
<pre class="cpp"><code>#ifdef _OPENMP
  coreseed = static_cast&lt;uint32_t&gt;(seeds[omp_get_thread_num()]);
#endif</code></pre>
<p>Provides the seed to each RNG instance using the ID number of each thread (<code>omp_get_thread_num()</code> is defined in <code>omp.h</code>). The rest of the code should be relative clear. Let us test it:</p>
<pre class="r"><code>par(mfrow = c(1, 2))
hist(rowSums(matrix(runif(n*nstep), n, nstep)), main = &quot;R&quot;, xlab = &quot;x&quot;)
hist(sumunif_sitmo_omp(n, nstep = nstep, seed = 1:4), main = &quot;Sitmo&quot;, xlab = &quot;x&quot;)</code></pre>
<p><img src="/sc2-2019/rcpp_advanced_III/1_OpenMP_files/figure-html/unnamed-chunk-20-1.png" width="576" style="display: block; margin: auto;" />
It seems to work fine. Let’s look at the CPU time:</p>
<pre class="r"><code>microbenchmark(R = rowSums(matrix(runif(n*nstep), n, nstep)),
               sitmo = sumunif_sitmo(n, nstep = nstep, seed = 1),
               sitmo_omp1 = sumunif_sitmo_omp(n, nstep = nstep, seeds = 1),
               sitmo_omp4 = sumunif_sitmo_omp(n, nstep = nstep, seeds = 1:4), 
               sitmo_omp16 = sumunif_sitmo_omp(n, nstep = nstep, seeds = 1:16), 
               unit = &quot;relative&quot;, 
               times = 1000
               )</code></pre>
<p>On the system described above, I get</p>
<pre class="r"><code>Unit: relative
        expr       min        lq     mean   median       uq       max neval
           R 15.064965 9.9710359 8.126831 9.398850 9.537932 2.7370000  1000
       sitmo  3.903483 2.5839086 2.054123 2.350338 2.430880 0.4575572  1000
  sitmo_omp1  3.891468 2.5765881 2.052102 2.341904 2.421889 0.4737860  1000
  sitmo_omp4  1.000000 1.0000000 1.000000 1.000000 1.000000 1.0000000  1000
 sitmo_omp16  1.108871 0.9717565 1.569470 1.386362 1.822677 1.1224609  1000</code></pre>
</div>
<div id="using-openmp-in-r-packages" class="section level3">
<h3>Using OpenMP in R packages</h3>
</div>


  <footer>
  

<script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>


<script type="text/javascript">
var sc_project=12110974;
var sc_invisible=1;
var sc_security="9b171880";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12110974/0/9b171880/1/"
alt="Web Analytics"></a></div></noscript>








  


<p align=right>

<a href='https://github.com/mfasiolo/sc2-2019/blob/master/content/rcpp_advanced_III/1_OpenMP.Rmd'>View source</a>

|

<a href='https://github.com/mfasiolo/sc2-2019/edit/master/content/rcpp_advanced_III/1_OpenMP.Rmd'>Edit source</a>

</p>





<script src="https://utteranc.es/client.js"
        repo="awllee/sc1-2019"
        issue-term="pathname"
        label="utterance"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>



  



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/tex.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



  
  <hr>
  <div class="copyright">© 2020 <a href="https://mfasiolo.github.io/">Matteo Fasiolo</a></div>
  
  </footer>
  </article>
  
  </body>
</html>

